{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.stats import linregress\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [\n",
    "    #'rdatatable_datatable',\n",
    "    #'facebook_react',\n",
    "    'freecad_freecad'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = list()\n",
    "issues_comments = list()\n",
    "pull_requests = list()\n",
    "pull_request_comments = list()\n",
    "\n",
    "for file in projects:\n",
    "    temp_df = pd.read_excel(f'Files/{file}_issues.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    issues.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_issues_comments.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    issues_comments.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_pull_requests.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    pull_requests.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_pull_request_comments.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    pull_request_comments.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues = pd.concat(issues)\n",
    "df_issues_comments = pd.concat(issues_comments)\n",
    "df_pull_requests = pd.concat(pull_requests)\n",
    "df_pull_requests_comments = pd.concat(pull_request_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues['created_by'] = df_issues['created_by']\\\n",
    "    .str.replace('https://api.github.com/users/', '', regex = False)\n",
    "\n",
    "df_pull_requests['created_by'] = df_pull_requests['created_by']\\\n",
    "    .str.replace('https://api.github.com/users/', '', regex = False)\n",
    "\n",
    "df_issues_comments['created_by'] = df_issues_comments['created_by']\\\n",
    "    .str.extract(r'login=\"([^\"]+)\"')\n",
    "\n",
    "df_pull_requests_comments['created_by'] = df_pull_requests_comments['created_by']\\\n",
    "    .str.extract(r'login=\"([^\"]+)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_users = pd.concat([\n",
    "        df_issues[['created_by', 'project']],\n",
    "        df_pull_requests[['created_by', 'project']],\n",
    "        df_issues_comments[['created_by', 'project']],\n",
    "        df_pull_requests_comments[['created_by', 'project']]\n",
    "    ])\\\n",
    "    .drop_duplicates()\\\n",
    "    .reset_index()\\\n",
    "    [['created_by', 'project']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_42788/2069917712.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pr_reviewers_by_month['created_at'] = pd.to_datetime(pr_reviewers_by_month['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "pr_reviewers_by_month = df_pull_requests_comments[['created_by', 'created_at', 'pull_request_id', 'project']]\n",
    "pr_reviewers_by_month['created_at'] = pd.to_datetime(pr_reviewers_by_month['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.drop_duplicates()\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.rename(columns={'pull_request_id': 'number_of_revisions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_42788/1794930000.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  issues_commented['created_at'] = pd.to_datetime(issues_commented['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "issues_commented = df_issues_comments[['created_by', 'created_at', 'issue_id', 'project']]\n",
    "issues_commented['created_at'] = pd.to_datetime(issues_commented['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "issues_commented = issues_commented.drop_duplicates()\n",
    "issues_commented = issues_commented.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "issues_commented = issues_commented.rename(columns={'issue_id': 'number_of_comments_issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_42788/2771644957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  issues_created['created_at'] = pd.to_datetime(issues_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "issues_created = df_issues[['created_by', 'created_at', 'id', 'project']]\n",
    "issues_created['created_at'] = pd.to_datetime(issues_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "issues_created = issues_created.drop_duplicates()\n",
    "issues_created = issues_created.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "issues_created = issues_created.rename(columns={'id': 'number_of_issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_42788/605893098.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pull_request_created['created_at'] = pd.to_datetime(pull_request_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "pull_request_created = df_pull_requests[['created_by', 'created_at', 'id', 'project']]\n",
    "pull_request_created['created_at'] = pd.to_datetime(pull_request_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "pull_request_created = pull_request_created.drop_duplicates()\n",
    "pull_request_created = pull_request_created.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "pull_request_created = pull_request_created.rename(columns={'id': 'number_of_pr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues_interaction = pd.concat([\n",
    "        df_issues_comments[['issue_id', 'created_by', 'created_at', 'project']],\n",
    "        df_issues[['id', 'created_by', 'created_at', 'project']].rename(columns = {'id': 'issue_id'})\n",
    "    ], ignore_index=True)\n",
    "\n",
    "df_pr_interaction = pd.concat(\n",
    "    [\n",
    "        df_pull_requests_comments[['pull_request_id', 'created_by', 'created_at', 'project']],\n",
    "        df_pull_requests[['id', 'created_by', 'created_at', 'project']].rename(columns = {'id': 'pull_request_id'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_issues_interaction['object'] = 'Issue'\n",
    "df_pr_interaction['object'] = 'PullRequest'\n",
    "\n",
    "df_interaction = pd.concat([\n",
    "        df_pr_interaction.rename(columns = {'pull_request_id': 'id'}),\n",
    "        df_issues_interaction.rename(columns = {'issue_id': 'id'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_interaction['created_at'] = pd.to_datetime(df_interaction['created_at']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interaction = df_interaction\\\n",
    "    .sort_values(by = ['object', 'created_at'])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "interactions = []\n",
    "interaction_points = defaultdict(int)\n",
    "\n",
    "for project in df_interaction['project'].unique():\n",
    "    temp_df = df_interaction[df_interaction['project'] == project]\n",
    "    \n",
    "    for obj in temp_df['object'].unique():\n",
    "        obj_df = temp_df[temp_df['object'] == obj]\n",
    "\n",
    "        for page in obj_df['id'].unique():\n",
    "            page_df = obj_df[obj_df['id'] == page]\n",
    "            \n",
    "            previous_users = set()\n",
    "\n",
    "            for _, row in page_df.iterrows():\n",
    "                current_user = row['created_by']\n",
    "                created_at = row['created_at']\n",
    "                \n",
    "                for user in previous_users:\n",
    "                    interaction_points[(current_user, user, created_at, project)] += 1\n",
    "                \n",
    "                previous_users.add(current_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.DataFrame(\n",
    "    [(dev_a, dev_b, created_at, project, points) for (dev_a, dev_b, created_at, project), points in interaction_points.items()],\n",
    "    columns=['Developer_A', 'Interacted_With', 'Created_At', 'Project', 'Points']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = interactions_df\\\n",
    "    .groupby(['Developer_A', 'Interacted_With', 'Created_At', 'Project'])\\\n",
    "    .agg(Total_Interactions_A_to_B=('Points', 'sum'))\\\n",
    "    .reset_index()\n",
    "\n",
    "reverse_interactions = interactions_df\\\n",
    "    .rename(columns={'Developer_A': 'Interacted_With', 'Interacted_With': 'Developer_A'})\\\n",
    "    .groupby(['Developer_A', 'Interacted_With', 'Created_At', 'Project'])\\\n",
    "    .agg(Total_Interactions_B_to_A = ('Points', 'sum'))\\\n",
    "    .reset_index()\n",
    "\n",
    "df = pd.merge(\n",
    "        aggregated, \n",
    "        reverse_interactions, \n",
    "        on = ['Developer_A', 'Interacted_With', 'Created_At', 'Project'], \n",
    "        how = 'outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "df['Relationship_Strength'] = df[['Total_Interactions_A_to_B', 'Total_Interactions_B_to_A']].min(axis=1)\n",
    "df = df[df['Developer_A'] != df['Interacted_With']]\n",
    "df = df.rename(columns={'Interacted_With': 'Developer_B', 'Created_At': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_metrics = []\n",
    "\n",
    "for project in df['Project'].drop_duplicates():\n",
    "    \n",
    "    temp_df = df[df['Project'] == project]\n",
    "    \n",
    "    for month, month_df in temp_df.groupby(temp_df['Date']):\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        \n",
    "        for _, row in month_df.iterrows():\n",
    "            G.add_edge(\n",
    "                row['Developer_A'], \n",
    "                row['Developer_B'], \n",
    "                weight=row['Relationship_Strength']\n",
    "            )\n",
    "        \n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        betweenness_centrality = nx.betweenness_centrality(G, weight='weight')\n",
    "        closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "        for user in G.nodes():\n",
    "            user_edges = list(G.edges(user, data=True))\n",
    "            num_relationships = len(user_edges)\n",
    "            \n",
    "            avg_strength = (\n",
    "                sum(edge_data['weight'] for _, _, edge_data in user_edges) / num_relationships\n",
    "                if num_relationships > 0 else 0\n",
    "            )\n",
    "\n",
    "            monthly_metrics.append({\n",
    "                'user': user,\n",
    "                'month': month,\n",
    "                'degree_centrality': degree_centrality.get(user, 0),\n",
    "                'betweenness_centrality': betweenness_centrality.get(user, 0),\n",
    "                'closeness_centrality': closeness_centrality.get(user, 0),\n",
    "                'num_relationships': num_relationships,\n",
    "                'avg_strength': avg_strength,\n",
    "                'project': project,\n",
    "            })\n",
    "\n",
    "\n",
    "    network_df = pd.DataFrame(monthly_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dim_users\\\n",
    "    .merge(\n",
    "        pr_reviewers_by_month,\n",
    "        on=['created_by', 'project'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        issues_created,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        issues_commented,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        pull_request_created,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .rename(\n",
    "        columns = {\n",
    "            'created_by': 'user',\n",
    "            'created_at': 'month'\n",
    "        }\n",
    "    )\\\n",
    "    .merge(\n",
    "        network_df,\n",
    "        on=['user', 'month', 'project']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = [\n",
    "    'number_of_revisions',\n",
    "    'number_of_issues',\n",
    "    'number_of_comments_issues',\n",
    "    'number_of_pr',\n",
    "    'degree_centrality',\n",
    "    'betweenness_centrality',\n",
    "    'closeness_centrality',\n",
    "    'num_relationships',\n",
    "    'avg_strength',\n",
    "]\n",
    "\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)\n",
    "df['inactive_month'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    group = group.sort_values(by='month', ascending=True)\n",
    "    group['month'] = pd.to_datetime(group['month'])\n",
    "    \n",
    "    start_month = group['month'].iloc[0]\n",
    "    end_month = group['month'].iloc[-1] + pd.DateOffset(months=12)\n",
    "    \n",
    "    full_months = pd.date_range(start=start_month, end=end_month, freq='MS')\n",
    "    full_months_period = full_months.to_period('M')\n",
    "        \n",
    "    existing_months_period = group['month'].dt.to_period('M')\n",
    "    missing_months = full_months_period.difference(existing_months_period)\n",
    "    \n",
    "    if not missing_months.empty:\n",
    "        for month in missing_months:\n",
    "            all_rows.append({\n",
    "                'user': developer,\n",
    "                'project': project,\n",
    "                'month': month.start_time.strftime('%Y-%m'),\n",
    "                'number_of_revisions': 0,\n",
    "                'number_of_issues': 0,\n",
    "                'number_of_comments_issues': 0,\n",
    "                'number_of_pr': 0,\n",
    "                'degree_centrality': 0,\n",
    "                'betweenness_centrality': 0,\n",
    "                'closeness_centrality': 0,\n",
    "                'num_relationships': 0,\n",
    "                'avg_strength': 0,\n",
    "                'inactive_month': True\n",
    "            })\n",
    "\n",
    "if all_rows:\n",
    "    missing_months_df = pd.DataFrame(all_rows)\n",
    "    df = pd.concat([df, missing_months_df], ignore_index=True).sort_values(by='month', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['month'] < '2024-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_year'] = pd.to_datetime(df['month']).dt.to_period('M')\n",
    "df = df.sort_values(by='month', ascending=True)\n",
    "regression_results = list()\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    for idx, current_month in enumerate(group['month']):\n",
    "        \n",
    "        current_month = pd.to_datetime(current_month)\n",
    "        start_month = current_month - pd.DateOffset(months=12)\n",
    "\n",
    "        full_months = pd.date_range(start=start_month, end=current_month, freq='MS')\n",
    "        full_months_period = full_months.to_period('M')\n",
    "        \n",
    "        group_filtered = group[\n",
    "            (group['month_year'] >= start_month.to_period('M')) & \n",
    "            (group['month_year'] <= current_month.to_period('M'))\n",
    "        ]\n",
    "        missing_months = full_months_period.difference(group_filtered['month_year'])\n",
    "        \n",
    "        list_missing_months = list() \n",
    "\n",
    "        for missing_month in missing_months:\n",
    "            missing_data = {\n",
    "                'month': pd.to_datetime(str(missing_month)).strftime('%Y-%m'),\n",
    "                'month_year': missing_month,\n",
    "                'user': developer,\n",
    "                'project': project,\n",
    "                'inactive_month': True,\n",
    "                'number_of_revisions': 0,\n",
    "                'number_of_issues': 0,\n",
    "                'number_of_comments_issues': 0,\n",
    "                'number_of_pr': 0,\n",
    "                'degree_centrality': 0,\n",
    "                'betweenness_centrality': 0,\n",
    "                'closeness_centrality': 0,\n",
    "                'num_relationships': 0,\n",
    "                'avg_strength': 0,\n",
    "            }\n",
    "            list_missing_months.append(missing_data)\n",
    "        \n",
    "        current_month_analysis = pd\\\n",
    "            .concat([group_filtered, pd.DataFrame(list_missing_months)], ignore_index=True)\\\n",
    "            .sort_values(by = 'month_year', ascending= False)\n",
    "        \n",
    "        for window in [3, 6, 9, 12]:\n",
    "            window_data = current_month_analysis.iloc[0 : window].reset_index(drop=True)\n",
    "            x = window_data.index\n",
    "            \n",
    "            for metric in [\n",
    "                'number_of_revisions', \n",
    "                'number_of_issues', \n",
    "                'number_of_comments_issues', \n",
    "                'number_of_pr', \n",
    "                'degree_centrality', \n",
    "                'betweenness_centrality', \n",
    "                'closeness_centrality',\n",
    "                'num_relationships', \n",
    "                'avg_strength'\n",
    "            ]:\n",
    "                y = window_data[metric]\n",
    "                slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "                \n",
    "                predicted_y = slope * x + intercept\n",
    "                residuals = y - predicted_y\n",
    "                std_dev = np.std(residuals)\n",
    "                \n",
    "                result = {\n",
    "                    'user': developer,\n",
    "                    'project': project,\n",
    "                    'current_month': current_month,\n",
    "                    f'{metric}_{window}_slope': slope,\n",
    "                    f'{metric}_{window}_intercept': intercept,\n",
    "                    f'{metric}_{window}_std_dev': std_dev\n",
    "                }\n",
    "                \n",
    "                regression_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = pd.DataFrame(regression_results)\n",
    "\n",
    "regression_df_pivot = regression_df.pivot_table(\n",
    "    index=['user', 'project', 'current_month'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "regression_df_pivot.columns = [f'{col}' for col in regression_df_pivot.columns]\n",
    "regression_df_pivot.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_columns = [\n",
    "    'avg_strength_3_intercept', 'avg_strength_3_slope', 'avg_strength_3_std_dev', \n",
    "    'avg_strength_6_intercept', 'avg_strength_6_slope', 'avg_strength_6_std_dev', \n",
    "    'avg_strength_9_intercept', 'avg_strength_9_slope', 'avg_strength_9_std_dev', \n",
    "    'avg_strength_12_intercept', 'avg_strength_12_slope', 'avg_strength_12_std_dev', \n",
    "    'betweenness_centrality_3_intercept', 'betweenness_centrality_3_slope', 'betweenness_centrality_3_std_dev', \n",
    "    'betweenness_centrality_6_intercept', 'betweenness_centrality_6_slope', 'betweenness_centrality_6_std_dev', \n",
    "    'betweenness_centrality_9_intercept', 'betweenness_centrality_9_slope', 'betweenness_centrality_9_std_dev', \n",
    "    'betweenness_centrality_12_intercept', 'betweenness_centrality_12_slope', 'betweenness_centrality_12_std_dev', \n",
    "    'closeness_centrality_3_intercept', 'closeness_centrality_3_slope', 'closeness_centrality_3_std_dev', \n",
    "    'closeness_centrality_6_intercept', 'closeness_centrality_6_slope', 'closeness_centrality_6_std_dev', \n",
    "    'closeness_centrality_9_intercept', 'closeness_centrality_9_slope', 'closeness_centrality_9_std_dev', \n",
    "    'closeness_centrality_12_intercept', 'closeness_centrality_12_slope', 'closeness_centrality_12_std_dev', \n",
    "    'degree_centrality_3_intercept', 'degree_centrality_3_slope', 'degree_centrality_3_std_dev', \n",
    "    'degree_centrality_6_intercept', 'degree_centrality_6_slope', 'degree_centrality_6_std_dev', \n",
    "    'degree_centrality_9_intercept', 'degree_centrality_9_slope', 'degree_centrality_9_std_dev', \n",
    "    'degree_centrality_12_intercept', 'degree_centrality_12_slope', 'degree_centrality_12_std_dev', \n",
    "    'num_relationships_3_intercept', 'num_relationships_3_slope', 'num_relationships_3_std_dev', \n",
    "    'num_relationships_6_intercept', 'num_relationships_6_slope', 'num_relationships_6_std_dev', \n",
    "    'num_relationships_9_intercept', 'num_relationships_9_slope', 'num_relationships_9_std_dev', \n",
    "    'num_relationships_12_intercept', 'num_relationships_12_slope', 'num_relationships_12_std_dev', \n",
    "    'number_of_comments_issues_12_intercept', 'number_of_comments_issues_12_slope', 'number_of_comments_issues_12_std_dev', \n",
    "    'number_of_comments_issues_3_intercept', 'number_of_comments_issues_3_slope', 'number_of_comments_issues_3_std_dev', \n",
    "    'number_of_comments_issues_6_intercept', 'number_of_comments_issues_6_slope', 'number_of_comments_issues_6_std_dev', \n",
    "    'number_of_comments_issues_9_intercept', 'number_of_comments_issues_9_slope', 'number_of_comments_issues_9_std_dev', \n",
    "    'number_of_issues_3_intercept', 'number_of_issues_3_slope', 'number_of_issues_3_std_dev', \n",
    "    'number_of_issues_6_intercept', 'number_of_issues_6_slope', 'number_of_issues_6_std_dev', \n",
    "    'number_of_issues_9_intercept', 'number_of_issues_9_slope', 'number_of_issues_9_std_dev', \n",
    "    'number_of_issues_12_intercept', 'number_of_issues_12_slope', 'number_of_issues_12_std_dev', \n",
    "    'number_of_pr_3_intercept', 'number_of_pr_3_slope', 'number_of_pr_3_std_dev', \n",
    "    'number_of_pr_6_intercept', 'number_of_pr_6_slope', 'number_of_pr_6_std_dev', \n",
    "    'number_of_pr_9_intercept', 'number_of_pr_9_slope', 'number_of_pr_9_std_dev', \n",
    "    'number_of_pr_12_intercept', 'number_of_pr_12_slope', 'number_of_pr_12_std_dev', \n",
    "    'number_of_revisions_3_intercept', 'number_of_revisions_3_slope', 'number_of_revisions_3_std_dev', \n",
    "    'number_of_revisions_6_intercept', 'number_of_revisions_6_slope', 'number_of_revisions_6_std_dev', \n",
    "    'number_of_revisions_9_intercept', 'number_of_revisions_9_slope', 'number_of_revisions_9_std_dev',\n",
    "    'number_of_revisions_12_intercept', 'number_of_revisions_12_slope', 'number_of_revisions_12_std_dev'\n",
    "]\n",
    "\n",
    "regression_df_pivot['turnover_num'] = regression_df_pivot[activity_columns].sum(axis=1)\n",
    "regression_df_pivot['turnover'] = regression_df_pivot['turnover_num'].apply(lambda x: 'dead' if x == 0 else 'active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_stats_list = list() \n",
    "\n",
    "for (developer, project), group in regression_df_pivot.groupby(['user', 'project']):\n",
    "\n",
    "    group = group.sort_values(by='current_month')\n",
    "    active = True \n",
    "    modified_group = []\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        if row['turnover'] == 'active': \n",
    "            active = True\n",
    "            modified_group.append(row) \n",
    "\n",
    "        elif row['turnover'] == 'dead' and active: \n",
    "            row['turnover'] = 'dead'\n",
    "            modified_group.append(row)\n",
    "            active = False \n",
    "\n",
    "        elif row['turnover'] == 'dead' and not active: \n",
    "            pass\n",
    "    \n",
    "    turnover_stats_list.append(modified_group)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(group) for group in turnover_stats_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_stats_list = list()\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    group = group.sort_values(by='current_month', ascending=False)\n",
    "    active = True\n",
    "    count = 0\n",
    "    modified_group = []\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        if row['turnover'] == 'active' and count == 0:\n",
    "            modified_group.append(row)\n",
    "        \n",
    "        elif row['turnover'] == 'dead':\n",
    "            active = False \n",
    "            count = 12 \n",
    "            row['turnover'] = 'dead' \n",
    "            modified_group.append(row)\n",
    "\n",
    "        else:\n",
    "            if count > 0:\n",
    "                count -= 1\n",
    "                if count == 0:\n",
    "                    row['turnover'] = 'last-worked-month'\n",
    "                else:\n",
    "                    row['turnover'] = 'pre-death'\n",
    "                modified_group.append(row)\n",
    "\n",
    "    turnover_stats_list.append(modified_group)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(group) for group in turnover_stats_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>project</th>\n",
       "      <th>current_month</th>\n",
       "      <th>avg_strength_12_intercept</th>\n",
       "      <th>avg_strength_12_slope</th>\n",
       "      <th>avg_strength_12_std_dev</th>\n",
       "      <th>avg_strength_3_intercept</th>\n",
       "      <th>avg_strength_3_slope</th>\n",
       "      <th>avg_strength_3_std_dev</th>\n",
       "      <th>avg_strength_6_intercept</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_revisions_3_slope</th>\n",
       "      <th>number_of_revisions_3_std_dev</th>\n",
       "      <th>number_of_revisions_6_intercept</th>\n",
       "      <th>number_of_revisions_6_slope</th>\n",
       "      <th>number_of_revisions_6_std_dev</th>\n",
       "      <th>number_of_revisions_9_intercept</th>\n",
       "      <th>number_of_revisions_9_slope</th>\n",
       "      <th>number_of_revisions_9_std_dev</th>\n",
       "      <th>turnover_num</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0penBrain</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>-0.379065</td>\n",
       "      <td>0.343202</td>\n",
       "      <td>1.473141</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>-0.086960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.952381</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.565501</td>\n",
       "      <td>-0.422222</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.367163</td>\n",
       "      <td>2.275958e+38</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0penBrain</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0.144839</td>\n",
       "      <td>0.264906</td>\n",
       "      <td>1.601083</td>\n",
       "      <td>0.044139</td>\n",
       "      <td>0.310440</td>\n",
       "      <td>0.038593</td>\n",
       "      <td>0.173967</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>-0.380952</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.586651</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.648980</td>\n",
       "      <td>2.124019e+38</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0penBrain</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>-0.475701</td>\n",
       "      <td>0.534544</td>\n",
       "      <td>2.353131</td>\n",
       "      <td>0.374709</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>0.105654</td>\n",
       "      <td>0.373731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>1.606534</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.632426</td>\n",
       "      <td>1.589016e+30</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0penBrain</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>-0.976797</td>\n",
       "      <td>0.802925</td>\n",
       "      <td>2.737924</td>\n",
       "      <td>0.566822</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.177463</td>\n",
       "      <td>0.653015</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.885618</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>1.616384</td>\n",
       "      <td>2.311111</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>2.640263</td>\n",
       "      <td>6.637926e+28</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0penBrain</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0.347748</td>\n",
       "      <td>0.555397</td>\n",
       "      <td>3.423497</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.305699</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>1.476190</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.935467</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>2.702537</td>\n",
       "      <td>6.103344e+28</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12940</th>\n",
       "      <td>ztx-lyghters</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>0.182669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.202550e+00</td>\n",
       "      <td>pre-death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12941</th>\n",
       "      <td>ztx-lyghters</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>-0.011655</td>\n",
       "      <td>0.179811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.158902e+00</td>\n",
       "      <td>pre-death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12942</th>\n",
       "      <td>ztx-lyghters</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>-0.016317</td>\n",
       "      <td>0.175436</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085050e+01</td>\n",
       "      <td>pre-death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12943</th>\n",
       "      <td>ztx-lyghters</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>-0.020979</td>\n",
       "      <td>0.169428</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.265071e+01</td>\n",
       "      <td>pre-death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12944</th>\n",
       "      <td>ztx-lyghters</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.161604</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180618e+01</td>\n",
       "      <td>last-worked-month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12945 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user          project current_month  avg_strength_12_intercept  \\\n",
       "0         0penBrain  freecad_freecad    2023-12-01                  -0.379065   \n",
       "1         0penBrain  freecad_freecad    2023-11-01                   0.144839   \n",
       "2         0penBrain  freecad_freecad    2023-10-01                  -0.475701   \n",
       "3         0penBrain  freecad_freecad    2023-09-01                  -0.976797   \n",
       "4         0penBrain  freecad_freecad    2023-08-01                   0.347748   \n",
       "...             ...              ...           ...                        ...   \n",
       "12940  ztx-lyghters  freecad_freecad    2023-04-01                   0.094017   \n",
       "12941  ztx-lyghters  freecad_freecad    2023-03-01                   0.119658   \n",
       "12942  ztx-lyghters  freecad_freecad    2023-02-01                   0.145299   \n",
       "12943  ztx-lyghters  freecad_freecad    2023-01-01                   0.170940   \n",
       "12944  ztx-lyghters  freecad_freecad    2022-12-01                   0.196581   \n",
       "\n",
       "       avg_strength_12_slope  avg_strength_12_std_dev  \\\n",
       "0                   0.343202                 1.473141   \n",
       "1                   0.264906                 1.601083   \n",
       "2                   0.534544                 2.353131   \n",
       "3                   0.802925                 2.737924   \n",
       "4                   0.555397                 3.423497   \n",
       "...                      ...                      ...   \n",
       "12940              -0.006993                 0.182669   \n",
       "12941              -0.011655                 0.179811   \n",
       "12942              -0.016317                 0.175436   \n",
       "12943              -0.020979                 0.169428   \n",
       "12944              -0.025641                 0.161604   \n",
       "\n",
       "       avg_strength_3_intercept  avg_strength_3_slope  avg_strength_3_std_dev  \\\n",
       "0                      0.025893              0.118750                0.051770   \n",
       "1                      0.044139              0.310440                0.038593   \n",
       "2                      0.374709              0.168182                0.105654   \n",
       "3                      0.566822              0.320513                0.177463   \n",
       "4                      0.852525              0.048485                0.305699   \n",
       "...                         ...                   ...                     ...   \n",
       "12940                  0.000000              0.000000                0.000000   \n",
       "12941                  0.000000              0.000000                0.000000   \n",
       "12942                 -0.111111              0.333333                0.157135   \n",
       "12943                  0.222222              0.000000                0.314270   \n",
       "12944                  0.555556             -0.333333                0.157135   \n",
       "\n",
       "       avg_strength_6_intercept  ...  number_of_revisions_3_slope  \\\n",
       "0                     -0.086960  ...                          0.0   \n",
       "1                      0.173967  ...                          1.0   \n",
       "2                      0.373731  ...                          0.0   \n",
       "3                      0.653015  ...                          2.0   \n",
       "4                      0.382354  ...                          1.5   \n",
       "...                         ...  ...                          ...   \n",
       "12940                 -0.031746  ...                          0.0   \n",
       "12941                  0.063492  ...                          0.0   \n",
       "12942                  0.158730  ...                          0.0   \n",
       "12943                  0.253968  ...                          0.0   \n",
       "12944                  0.349206  ...                          0.0   \n",
       "\n",
       "       number_of_revisions_3_std_dev  number_of_revisions_6_intercept  \\\n",
       "0                           0.000000                        -0.952381   \n",
       "1                           0.471405                        -0.380952   \n",
       "2                           0.942809                         0.428571   \n",
       "3                           1.885618                         1.809524   \n",
       "4                           2.121320                         1.476190   \n",
       "...                              ...                              ...   \n",
       "12940                       0.000000                         0.000000   \n",
       "12941                       0.000000                         0.000000   \n",
       "12942                       0.000000                         0.000000   \n",
       "12943                       0.000000                         0.000000   \n",
       "12944                       0.000000                         0.000000   \n",
       "\n",
       "       number_of_revisions_6_slope  number_of_revisions_6_std_dev  \\\n",
       "0                         0.914286                       1.565501   \n",
       "1                         0.885714                       1.586651   \n",
       "2                         0.828571                       1.606534   \n",
       "3                         0.542857                       1.616384   \n",
       "4                         1.142857                       1.935467   \n",
       "...                            ...                            ...   \n",
       "12940                     0.000000                       0.000000   \n",
       "12941                     0.000000                       0.000000   \n",
       "12942                     0.000000                       0.000000   \n",
       "12943                     0.000000                       0.000000   \n",
       "12944                     0.000000                       0.000000   \n",
       "\n",
       "       number_of_revisions_9_intercept  number_of_revisions_9_slope  \\\n",
       "0                            -0.422222                     0.633333   \n",
       "1                            -0.555556                     0.916667   \n",
       "2                             0.066667                     0.983333   \n",
       "3                             2.311111                     0.450000   \n",
       "4                             3.266667                     0.266667   \n",
       "...                                ...                          ...   \n",
       "12940                         0.000000                     0.000000   \n",
       "12941                         0.000000                     0.000000   \n",
       "12942                         0.000000                     0.000000   \n",
       "12943                         0.000000                     0.000000   \n",
       "12944                         0.000000                     0.000000   \n",
       "\n",
       "       number_of_revisions_9_std_dev  turnover_num           turnover  \n",
       "0                           1.367163  2.275958e+38             active  \n",
       "1                           1.648980  2.124019e+38             active  \n",
       "2                           1.632426  1.589016e+30             active  \n",
       "3                           2.640263  6.637926e+28             active  \n",
       "4                           2.702537  6.103344e+28             active  \n",
       "...                              ...           ...                ...  \n",
       "12940                       0.000000  6.202550e+00          pre-death  \n",
       "12941                       0.000000  7.158902e+00          pre-death  \n",
       "12942                       0.000000  1.085050e+01          pre-death  \n",
       "12943                       0.000000  1.265071e+01          pre-death  \n",
       "12944                       0.000000  1.180618e+01  last-worked-month  \n",
       "\n",
       "[12945 rows x 113 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
