{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Value\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../../Data/\"\n",
    "\n",
    "file_list = glob.glob(os.path.join(folder_path, \"*.parquet\"))\n",
    "\n",
    "df = [pd.read_parquet(file) for file in file_list]\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = train_test_split(df, train_size=50000, stratify=df['time_to_stop_activity'], random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns = [\n",
    "        \"user\", \n",
    "        'project', \n",
    "        'current_month', \n",
    "        'turnover_num',\n",
    "        'turnover',\n",
    "        'betweenness_centrality_12_intercept',\n",
    "        'betweenness_centrality_12_slope', \n",
    "        'betweenness_centrality_12_std_dev',\n",
    "        'betweenness_centrality_3_intercept', \n",
    "        'betweenness_centrality_3_slope',\n",
    "        'betweenness_centrality_3_std_dev',\n",
    "        'betweenness_centrality_6_intercept', \n",
    "        'betweenness_centrality_6_slope',\n",
    "        'betweenness_centrality_6_std_dev',\n",
    "        'betweenness_centrality_9_intercept', \n",
    "        'betweenness_centrality_9_slope',\n",
    "        'betweenness_centrality_9_std_dev'\n",
    "    ], axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(np.float64)\n",
    "df = df.replace([np.inf], np.nan)\n",
    "\n",
    "for column in df.columns:\n",
    "    max_value = df[column].max(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)\n",
    "\n",
    "df = df.replace([-np.inf], np.nan)\n",
    "\n",
    "for column in df.columns:\n",
    "    max_value = df[column].min(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    max_value = df[column].max(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean') \n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = ['time_to_stop_activity'], axis = 1).values\n",
    "y = df['time_to_stop_activity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size = 0.3, \n",
    "    random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, X_train, Y_train, X_test, Y_test):\n",
    "    svr = SVR(kernel='rbf', C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    print(f'{regularization} - {tolerance} finished')\n",
    "    \n",
    "    return {\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = [\n",
    "    (regularization, tolerance) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>13.390178</td>\n",
       "      <td>13.280265</td>\n",
       "      <td>13.160565</td>\n",
       "      <td>12.939294</td>\n",
       "      <td>12.402443</td>\n",
       "      <td>11.890757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>12.479996</td>\n",
       "      <td>12.371040</td>\n",
       "      <td>12.262814</td>\n",
       "      <td>12.070211</td>\n",
       "      <td>11.604842</td>\n",
       "      <td>11.199720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>12.075603</td>\n",
       "      <td>11.978575</td>\n",
       "      <td>11.881581</td>\n",
       "      <td>11.702694</td>\n",
       "      <td>11.286046</td>\n",
       "      <td>10.960991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>11.928595</td>\n",
       "      <td>11.842577</td>\n",
       "      <td>11.745101</td>\n",
       "      <td>11.578240</td>\n",
       "      <td>11.186954</td>\n",
       "      <td>10.889238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>12.387036</td>\n",
       "      <td>12.311828</td>\n",
       "      <td>12.221274</td>\n",
       "      <td>12.026256</td>\n",
       "      <td>11.558197</td>\n",
       "      <td>11.201904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>15.856629</td>\n",
       "      <td>15.563041</td>\n",
       "      <td>15.472540</td>\n",
       "      <td>14.541930</td>\n",
       "      <td>13.941658</td>\n",
       "      <td>12.875893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance            0.01       0.05       0.10       0.20       0.50  \\\n",
       "regularization                                                          \n",
       "0.1             13.390178  13.280265  13.160565  12.939294  12.402443   \n",
       "1.0             12.479996  12.371040  12.262814  12.070211  11.604842   \n",
       "10.0            12.075603  11.978575  11.881581  11.702694  11.286046   \n",
       "100.0           11.928595  11.842577  11.745101  11.578240  11.186954   \n",
       "1000.0          12.387036  12.311828  12.221274  12.026256  11.558197   \n",
       "10000.0         15.856629  15.563041  15.472540  14.541930  13.941658   \n",
       "\n",
       "tolerance            1.00  \n",
       "regularization             \n",
       "0.1             11.890757  \n",
       "1.0             11.199720  \n",
       "10.0            10.960991  \n",
       "100.0           10.889238  \n",
       "1000.0          11.201904  \n",
       "10000.0         12.875893  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1.302288</td>\n",
       "      <td>1.326845</td>\n",
       "      <td>1.361401</td>\n",
       "      <td>1.430852</td>\n",
       "      <td>1.640659</td>\n",
       "      <td>1.989418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.263937</td>\n",
       "      <td>1.286779</td>\n",
       "      <td>1.320262</td>\n",
       "      <td>1.389101</td>\n",
       "      <td>1.598426</td>\n",
       "      <td>1.949192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1.244891</td>\n",
       "      <td>1.266640</td>\n",
       "      <td>1.299250</td>\n",
       "      <td>1.369076</td>\n",
       "      <td>1.579936</td>\n",
       "      <td>1.933765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>1.244098</td>\n",
       "      <td>1.267537</td>\n",
       "      <td>1.300010</td>\n",
       "      <td>1.367794</td>\n",
       "      <td>1.577872</td>\n",
       "      <td>1.928193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>1.294939</td>\n",
       "      <td>1.288773</td>\n",
       "      <td>1.322311</td>\n",
       "      <td>1.390511</td>\n",
       "      <td>1.596273</td>\n",
       "      <td>1.941795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>1.671229</td>\n",
       "      <td>1.690220</td>\n",
       "      <td>1.676505</td>\n",
       "      <td>1.418460</td>\n",
       "      <td>1.588372</td>\n",
       "      <td>1.930504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance           0.01      0.05      0.10      0.20      0.50      1.00\n",
       "regularization                                                            \n",
       "0.1             1.302288  1.326845  1.361401  1.430852  1.640659  1.989418\n",
       "1.0             1.263937  1.286779  1.320262  1.389101  1.598426  1.949192\n",
       "10.0            1.244891  1.266640  1.299250  1.369076  1.579936  1.933765\n",
       "100.0           1.244098  1.267537  1.300010  1.367794  1.577872  1.928193\n",
       "1000.0          1.294939  1.288773  1.322311  1.390511  1.596273  1.941795\n",
       "10000.0         1.671229  1.690220  1.676505  1.418460  1.588372  1.930504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_absolute_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>-0.092762</td>\n",
       "      <td>-0.083792</td>\n",
       "      <td>-0.074023</td>\n",
       "      <td>-0.055966</td>\n",
       "      <td>-0.012154</td>\n",
       "      <td>0.029605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.018483</td>\n",
       "      <td>-0.009591</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.052938</td>\n",
       "      <td>0.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.030354</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.078955</td>\n",
       "      <td>0.105482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.033537</td>\n",
       "      <td>0.041492</td>\n",
       "      <td>0.055109</td>\n",
       "      <td>0.087041</td>\n",
       "      <td>0.111338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>-0.010896</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.056745</td>\n",
       "      <td>0.085821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>-0.294047</td>\n",
       "      <td>-0.270088</td>\n",
       "      <td>-0.262702</td>\n",
       "      <td>-0.186755</td>\n",
       "      <td>-0.137768</td>\n",
       "      <td>-0.050792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance           0.01      0.05      0.10      0.20      0.50      1.00\n",
       "regularization                                                            \n",
       "0.1            -0.092762 -0.083792 -0.074023 -0.055966 -0.012154  0.029605\n",
       "1.0            -0.018483 -0.009591 -0.000759  0.014960  0.052938  0.086000\n",
       "10.0            0.014520  0.022438  0.030354  0.044952  0.078955  0.105482\n",
       "100.0           0.026517  0.033537  0.041492  0.055109  0.087041  0.111338\n",
       "1000.0         -0.010896 -0.004759  0.002631  0.018547  0.056745  0.085821\n",
       "10000.0        -0.294047 -0.270088 -0.262702 -0.186755 -0.137768 -0.050792"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='r2_score'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressorBenchmark.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Improvement\n",
    "Once the model has not a good performance, we are looking methods and techniques to improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Kernel Trick**\n",
    "SVM can model non-linear relationships between features by using the kernel trick. The default kernel is rbf (Radial Basis Function), but you can experiment with other kernels like:\n",
    "\n",
    "- Linear Kernel: If your data is linearly separable, the linear kernel might be the best choice.\n",
    "- Polynomial Kernel: Captures polynomial relationships between data points. You can control the degree of the polynomial to fit higher-order relationships.\n",
    "- Sigmoid Kernel: Similar to a neural network activation function, this kernel maps data into a hyperbolic tangent space.\n",
    "\n",
    "Action: Try different kernels and see which works best for your data. For non-linear data, rbf is usually a good default, but for linear data, a linear kernel might perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, kernel, X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    svr = SVR(kernel=kernel, C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'kernel': kernel,\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }\n",
    "\n",
    "param_combinations = [\n",
    "    (regularization, tolerance, kernel) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "    for kernel in ['rbf', 'linear', 'poly']\n",
    "]\n",
    "\n",
    "total_tasks = len(param_combinations)\n",
    "\n",
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, kernel, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol, kernel in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressor_KernelTrick_Benchmark.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'rbf']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'linear']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'poly']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Feature Scaling**\n",
    "SVM is sensitive to the scale of the features. Features with larger numerical ranges dominate the decision boundary, so proper scaling is essential. You are already using StandardScaler, but you can also try:\n",
    "\n",
    "- MinMaxScaler: Rescales features into a range, typically [0, 1]. This might work better if your features have different scales.\n",
    "- RobustScaler: This is more robust to outliers because it scales the data based on the median and the interquartile range instead of the mean and standard deviation.\n",
    "\n",
    "Action: Experiment with different scalers and check how each affects the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size = 0.3, \n",
    "    random_state = 11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, scaler, X_train, Y_train, X_test, Y_test):\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    svr = SVR(kernel='rbf', C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'scaler': type(scaler).__name__,\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = [\n",
    "    (regularization, tolerance, scaler) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "    for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, scaler, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol, scaler in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressor_FeatureScaler_Benchmark.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'StandardScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'RobustScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'MinMaxScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Outliers\n",
    "SVM is highly sensitive to outliers, as they can significantly influence the decision boundary and margins. Outliers can distort the hyperplane, leading to poor generalization.\n",
    "\n",
    "- Outlier Detection: Before training the model, perform outlier detection (e.g., using Z-scores, IQR, or visualizations like box plots) and remove or adjust them.\n",
    "- Adjust Epsilon: If your model has many outliers, you may want to increase epsilon to create a wider margin and minimize the effect of outliers.\n",
    "\n",
    "Action: Identify and handle outliers by removing or transforming them to see if performance improves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
